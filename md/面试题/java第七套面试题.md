# 加锁有什么机制？

**Java线程 加锁机制：synchronized、Lock、Condition**

**1.synchronized**

把代码块声明为 synchronized，有两个重要后果，通常是指该代码具有 **原子性（atomicity）**和 **可见性（visibility）**。

**原子性**

原子性意味着个时刻，只有一个线程能够执行一段代码，这段代码通过一个monitor object保护。从而防止多个线程在更新共享状态时相互冲突。

**可见性**

可见性则更为微妙，它要对付内存缓存和编译器优化的各种反常行为。它必须确保释放锁之前对共享数据做出的更改对于随后获得该锁的另一个线程是可见的 。

作用：如果没有同步机制提供的这种可见性保证，线程看到的共享变量可能是修改前的值或不一致的值，这将引发许多严重问题。

原理：当对象获取锁时，它首先使自己的高速缓存无效，这样就可以保证直接从主内存中装入变量。 同样，在对象释放锁之前，它会刷新其高速缓存，强制使已做的任何更改都出现在主内存中。 这样，会保证在同一个锁上同步的两个线程看到在 synchronized 块内修改的变量的相同值。

 

一般来说，线程以某种不必让其他线程立即可以看到的方式（不管这些线程在寄存器中、在处理器特定的缓存中，还是通过指令重排或者其他编译器优化），不受缓存变量值的约束，但是如果开发人员使用了同步，那么运行库将确保某一线程对变量所做的更新先于对现有`synchronized` 块所进行的更新，当进入由同一监控器（lock）保护的另一个`synchronized` 块时，将立刻可以看到这些对变量所做的更新。类似的规则也存在于`volatile`变量上。

——volatile只保证可见性，不保证原子性！

**何时要同步**

可见性同步的基本规则是在以下情况中必须同步： 

1. 读取上一次可能是由另一个线程写入的变量 
2. 写入下一次可能由另一个线程读取的变量

一致性同步：当修改多个相关值时，您想要其它线程原子地看到这组更改—— 要么看到全部更改，要么什么也看不到。

这适用于相关数据项（如粒子的位置和速率）和元数据项（如链表中包含的数据值和列表自身中的数据项的链）。

 

在某些情况中，您不必用同步来将数据从一个线程传递到另一个，因为 JVM 已经隐含地为您执行同步。这些情况包括：

1. 由静态初始化器（在静态字段上或 static{} 块中的初始化器）
2. 初始化数据时 
3. 访问 final 字段时 ——final对象呢？
4. 在创建线程之前创建对象时 
5. 线程可以看见它将要处理的对象时

**synchronize的限制**

synchronized是不错，但它并不完美。它有一些功能性的限制：

1. 它无法中断一个正在等候获得锁的线程；
2. 也无法通过投票得到锁，如果不想等下去，也就没法得到锁；
3. 同步还要求锁的释放只能在与获得锁所在的堆栈帧相同的堆栈帧中进行，多数情况下，这没问题（而且与异常处理交互得很好），但是，确实存在一些非块结构的锁定更合适的情况。

 

**2、ReentrantLock**

`Java.util.concurrent.lock` 中的`Lock` 框架是锁定的一个抽象，它允许把锁定的实现作为 Java 类，而不是作为语言的特性来实现。这就为`Lock` 的多种实现留下了空间，各种实现可能有不同的调度算法、性能特性或者锁定语义。

`ReentrantLock` 类实现了`Lock` ，它拥有与`synchronized` 相同的并发性和内存语义，但是添加了类似锁投票、定时锁等候和可中断锁等候的一些特性。此外，它还提供了在激烈争用情况下更佳的性能。（换句话说，当许多线程都想访问共享资源时，JVM 可以花更少的时候来调度线程，把更多时间用在执行线程上。

~~~~java
class ResourceClass {    
    private Lock lock = new ReentrantLock();// 锁对象    
  
    public void output(String name) {           
        lock.lock();      // 得到锁    
  
        try {    
            for(int i = 0; i < name.length(); i++) {    
                System.out.print(name.charAt(i));    
            }    
        } finally {    
            lock.unlock();// 释放锁    
        }    
    }    
} 
~~~~

区别：

需要注意的是，用sychronized修饰的方法或者语句块在代码执行完之后锁自动释放，而是用Lock需要我们手动释放锁，所以为了保证锁最终被释放(发生异常情况)，要把互斥区放在try内，释放锁放在finally内!!!

**3、读写锁ReadWriteLock**

与互斥锁定相比，读-写锁定允许对共享数据进行更高级别的并发访问。虽然一次只有一个线程（writer 线程）可以修改共享数据，但在许多情况下，任何数量的线程可以同时读取共享数据（reader 线程）

从理论上讲，与互斥锁定相比，使用读-写锁定所允许的并发性增强将带来更大的性能提高。

在实践中，只有在多处理器上并且只在访问模式适用于共享数据时，才能完全实现并发性增强。——例如，某个最初用数据填充并且之后不经常对其进行修改的 collection，因为经常对其进行搜索（比如搜索某种目录），所以这样的 collection 是使用读-写锁定的理想候选者。

 **4、线程间通信Condition**

Condition可以替代传统的线程间通信，用await()替换wait()，用signal()替换notify()，用signalAll()替换notifyAll()。

——为什么方法名不直接叫wait()/notify()/nofityAll()？因为Object的这几个方法是final的，不可重写！

 

传统线程的通信方式，Condition都可以实现。

注意，Condition是被绑定到Lock上的，要创建一个Lock的Condition必须用newCondition()方法。

 

Condition的强大之处在于它可以为多个线程间建立不同的Condition

看JDK文档中的一个例子：假定有一个绑定的缓冲区，它支持 put 和 take 方法。如果试图在空的缓冲区上执行take 操作，则在某一个项变得可用之前，线程将一直阻塞；如果试图在满的缓冲区上执行 put 操作，则在有空间变得可用之前，线程将一直阻塞。我们喜欢在单独的等待 set 中保存put 线程和take 线程，这样就可以在缓冲区中的项或空间变得可用时利用最佳规划，一次只通知一个线程。可以使用两个`Condition`实例来做到这一点。

——其实就是java.util.concurrent.ArrayBlockingQueue的功能

````java
class BoundedBuffer {  
  final Lock lock = new ReentrantLock();          //锁对象  
  final Condition notFull  = lock.newCondition(); //写线程锁  
  final Condition notEmpty = lock.newCondition(); //读线程锁  
  
  final Object[] items = new Object[100];//缓存队列  
  int putptr;  //写索引  
  int takeptr; //读索引  
  int count;   //队列中数据数目  
  
  //写  
  public void put(Object x) throws InterruptedException {  
    lock.lock(); //锁定  
    try {  
      // 如果队列满，则阻塞<写线程>  
      while (count == items.length) {  
        notFull.await();   
      }  
      // 写入队列，并更新写索引  
      items[putptr] = x;   
      if (++putptr == items.length) putptr = 0;   
      ++count;  
  
      // 唤醒<读线程>  
      notEmpty.signal();   
    } finally {   
      lock.unlock();//解除锁定   
    }   
  }  
  
  //读   
  public Object take() throws InterruptedException {   
    lock.lock(); //锁定   
    try {  
      // 如果队列空，则阻塞<读线程>  
      while (count == 0) {  
         notEmpty.await();  
      }  
  
      //读取队列，并更新读索引  
      Object x = items[takeptr];   
      if (++takeptr == items.length) takeptr = 0;  
      --count;  
  
      // 唤醒<写线程>  
      notFull.signal();   
      return x;   
    } finally {   
      lock.unlock();//解除锁定   
    }   
  }   

````

  优点：

假设缓存队列中已经存满，那么阻塞的肯定是写线程，唤醒的肯定是读线程，相反，阻塞的肯定是读线程，唤醒的肯定是写线程。

那么假设只有一个Condition会有什么效果呢？缓存队列中已经存满，这个Lock不知道唤醒的是读线程还是写线程了，如果唤醒的是读线程，皆大欢喜，如果唤醒的是写线程，那么线程刚被唤醒，又被阻塞了，这时又去唤醒，这样就浪费了很多时间。  



# 数据库水平切分，垂直切分的设计思路和切分顺序?

**为什么要拆分数据库?**

单体项目在构建之初，数据库的负载和数据量都不大，所以不需要对数据库做拆分，小型财务系统、文书系统、ERP系统、OA系统，用一个MySQL数据库实例基本就够用了。

就像《淘宝技术这十年》里面说到的，电商业务的数据量增长飞快，所以最开始的PHP+MySQL的架构已经不能满足实际要求了，于是淘宝想到的第一个办法就是把MySQL替换成Oracle。但是没过了多久，在08年前后，单节点的Oracle数据库也不好用了，于是淘宝终于告别了单节点数据库，开始拆分数据库。从一个节点，变成多个节点。

拆分数据库是有讲究的，比如说拆分方法有两种：垂直切分和水平切分。那你是先水平切分还是垂直切分呢？顺序无所谓？不，顺序有所为，次序绝对不能错：**先水平切分，然后垂直切分**。

**垂直拆分的思路**

垂直切分是根据业务来拆分数据库，同一类业务的数据表拆分到一个独立的数据库，另一类的数据表拆分到其他数据库。

比如说一个新零售的电商数据库，我们可以把跟商品相关的数据表拆分成一个数据库，然后在这些数据表的基础之上，构建出商品系统。比如用JAVA或者PHP语言，创建出一个商城系统。然后把跟进销存相关的数据表拆分到另外一个数据库上，再用程序构建出仓库系统。

```
垂直切分可以降低单节点数据库的负载。原来所有数据表都放在一个数据库节点上，无疑所有的读写请求也都发到这个MySQL上面，所以数据库的负载太高。如果把一个节点的数据库拆分成多个MySQL数据库，这样就可以有效的降低每个MySQL数据库的负载。
```

**水平切分的思路**

水平切分是按照某个字段的某种规则，把数据切分到多张数据表。一张数据表化整为零，拆分成多张数据表，这样就可以起到缩表的效果了.

很多人，都会水平切分存在误解，以为水平切分出来的数据表必须保存在不同的MySQL节点上。其实水平切分出来的数据表也可以保存在一个MySQL节点上面。不是水平切分一定需要多个MySQL节点。为什么这么说呢？

许多人不知道MySQL自带一种数据分区的技术，可以把一张表的数据，按照特殊规则，切分存储在不同的目录下。如果我们给Linux主机挂载了多块硬盘，我们完全可以利用MySQL分区技术，把一张表的数据切分存储在多个硬盘上。这样就由原来一块硬盘有限的IO能力，升级成了多个磁盘增强型的IO。

````
水平切分可以把数据切分到多张数据表，可以起到缩表的作用。

但是也不是所有的数据表都要做水平切分。数据量较大的数据表才需要做数据切分，比如说电商系统中的，用户表、商品表、产品表、地址表、订单表等等。有些数据表就不需要切分，因为数据量不多，比如说品牌表、供货商表、仓库表，这些都是不需要切分的。

````

**为什么先做水平切分,后做垂直切分**

随着数据量的增加，最先应该做的是数据分片，利用多块硬盘来增大数据IO能力和存储空间，这么做的成本是最低的。几块硬盘的钱就能收获不错的IO性能。

进入到下一个阶段，数据量继续增大，这时候我们应该把数据切分到多个MySQL节点上，用MyCat管理数据切分。当然还要做数据的读写分离等等，这里不展开讨论。在后台做水平切分的同时，业务系统也可以引入负载均衡、分布式架构等等。理论上，使用了冷热数据分离之后，水平切分这种方式可以继续维持很长一段时间，数据量再大也不怕，定期归档就好了。

数据库到了水平切分的阶段，数据量的增加已经不是更改架构设计的主要原因了。反而这个阶段业务系统承受不住了，如果再不对系统做模块拆分，业务系统也撑不下去了，所以按照模块和业务，把一个系统拆分成若干子系统。若干子系统之间，数据相对独立。比如淘宝不会跟支付支付宝分享全部数据，共享同一套数据表，这也影响各自业务的发展。所以就要弄垂直切分了，把数据表归类，拆分成若干个数据库系统。

讲到这里，你仔细想想。如果过早的对数据库做了垂直切分，势必要重新构建若干独立的业务系统，工作量太巨大。水平切分并不需要业务系统做大幅度的修改，因此说应该先从水平切分开始做。



# Redis如何解决key冲突？

1、业务隔离

不同的业务使用不同的redis集群，或者协议使用redis的不同db。

2、良好的Redis Key的设计

格式：业务标识：系统名称：模块名称：关键词简写

比如：保险：用户管理：用户申请：手机号

Redis Key：bx:um:reg:mobile

以上在实际的生产环境中，应该同时存在。



# 如何保证数据库与redis缓存一致的?

**将不一致分为三种情况：**

**1. 数据库有数据，缓存没有数据；**

**2. 数据库有数据，缓存也有数据，数据不相等；**

**3. 数据库没有数据，缓存有数据。**

在讨论这三种情况之前，先说明一下我使用缓存的策略，也是大多数人使用的策略，叫做 Cache Aside Pattern。简而言之，就是

**1. 首先尝试从缓存读取，读到数据则直接返回；如果读不到，就读数据库，并将数据会写到缓存，并返回。**

**2. 需要更新数据时，先更新数据库，然后把缓存里对应的数据失效掉（删掉）。**

读的逻辑大家都很容易理解，谈谈更新。如果不采取我提到的这种更新方法，你还能想到什么更新方法呢？大概会是：先删除缓存，然后再更新数据库。这么做引发的问题是，如果A,B两个线程同时要更新数据，并且A,B已经都做完了删除缓存这一步，接下来，A先更新了数据库，C线程读取数据，由于缓存没有，则查数据库，并把A更新的数据，写入了缓存，最后B更新数据库。那么缓存和数据库的值就不一致了。另外有人会问，如果采用你提到的方法，为什么最后是把缓存的数据删掉，而不是把更新的数据写到缓存里。这么做引发的问题是，如果A,B两个线程同时做数据更新，A先更新了数据库，B后更新数据库，则此时数据库里存的是B的数据。而更新缓存的时候，是B先更新了缓存，而A后更新了缓存，则缓存里是A的数据。这样缓存和数据库的数据也不一致。按照我提到的这种更新缓存的策略，理论上也是有不一致的风险的，之前在其他的博客文章有看到过，只不过概率很小，我们暂时可以不考虑，后面我们有其他手段来补救。讨论完使用缓存的策略，我们再来看这三种不一致的情况。

**1. 对于第一种，在读数据的时候，会自动把数据库的数据写到缓存，因此不一致自动消除.**

**2. 对于第二种，数据最终变成了不相等，但他们之前在某一个时间点一定是相等的（不管你使用懒加载还是预加载的方式，在缓存加载的那一刻，它一定和数据库一致）。这种不一致，一定是由于你更新数据所引发的。前面我们讲了更新数据的策略，先更新数据库，然后删除缓存。因此，不一致的原因，一定是数据库更新了，但是删除缓存失败了。**

**3. 对于第三种，情况和第二种类似，你把数据库的数据删了，但是删除缓存的时候失败了。**

**因此，最终的结论是，需要解决的不一致，产生的原因是更新数据库成功，但是删除缓存失败。**

解决方案大概有以下几种：

**1. 对删除缓存进行重试，数据的一致性要求越高，我越是重试得快。**

**2. 定期全量更新，简单地说，就是我定期把缓存全部清掉，然后再全量加载。**

**3. 给所有的缓存一个失效期。**

第三种方案可以说是一个大杀器，任何不一致，都可以靠失效期解决，失效期越短，数据一致性越高。但是失效期越短，查数据库就会越频繁。因此失效期应该根据业务来定。

**并发不高的情况：**

**读: 读redis->没有，读mysql->把mysql数据写回redis，有的话直接从redis中取；**

**写: 写mysql->成功，再写redis；**

**并发高的情况：**

**读: 读redis->没有，读mysql->把mysql数据写回redis，有的话直接从redis中取；**

**写：异步话，先写入redis的缓存，就直接返回；定期或特定动作将数据保存到mysql，可以做到多次更新，一次保存；**



# 项目中消息队列怎么用的？使用哪些具体业务场景？

消息队列中间件是分布式系统中重要的组件，主要解决应用耦合，异步消息，流量削锋等问题

实现高性能，高可用，可伸缩和最终一致性架构

使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ



**应用场景**

异步处理:

场景说明：用户注册后，需要发注册邮件和注册短信。传统的做法有两种 1.串行的方式；2.并行方式

（1）串行方式：将注册信息写入数据库成功后，发送注册邮件，再发送注册短信。以上三个任务全部完成后，返回给客户端

![](img\snipaste20200119_150843.png)

（2）并行方式：将注册信息写入数据库成功后，发送注册邮件的同时，发送注册短信。以上三个任务完成后，返回给客户端。与串行的差别是，并行的方式可以提高处理的时间

假设三个业务节点每个使用50毫秒钟，不考虑网络等其他开销，则串行方式的时间是150毫秒，并行的时间可能是100毫秒。

![](img\snipaste20200119_150941.png)

因为CPU在单位时间内处理的请求数是一定的，假设CPU1秒内吞吐量是100次。则串行方式1秒内CPU可处理的请求量是7次（1000/150）。并行方式处理的请求量是10次（1000/100）

引入消息队列，将不是必须的业务逻辑，异步处理。改造后的架构如下：

![](img\snipaste20200119_151013.png)

按照以上约定，用户的响应时间相当于是注册信息写入数据库的时间，也就是50毫秒。注册邮件，发送短信写入消息队列后，直接返回，因此写入消息队列的速度很快，基本可以忽略，因此用户的响应时间可能是50毫秒。因此架构改变后，系统的吞吐量提高到每秒20 QPS。比串行提高了3倍，比并行提高了两倍

应用解耦:

场景说明：用户下单后，订单系统需要通知库存系统。传统的做法是，订单系统调用库存系统的接口。如下图

![](img\snipaste20200119_151313.png)

传统模式的缺点：

- 假如库存系统无法访问，则订单减库存将失败，从而导致订单失败
- 订单系统与库存系统耦合

如何解决以上问题呢？引入应用消息队列后的方案，如下图：

![](img\snipaste20200119_151408.png)

- 订单系统：用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功
- 库存系统：订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作
- 假如：在下单时库存系统不能正常使用。也不影响正常下单，因为下单后，订单系统写入消息队列就不再关心其他的后续操作了。实现订单系统与库存系统的应用解耦

流量削峰:

流量削锋也是消息队列中的常用场景，一般在秒杀或团抢活动中使用广泛

应用场景：秒杀活动，一般会因为流量过大，导致流量暴增，应用挂掉。为解决这个问题，一般需要在应用前端加入消息队列。

- 可以控制活动的人数

- 可以缓解短时间内高流量压垮应用

  ![](E:\构图\md\面试题\img\snipaste20200119_151519.png)

  

  - 用户的请求，服务器接收后，首先写入消息队列。假如消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面
  - 秒杀业务根据消息队列中的请求信息，再做后续处理

  

# JVM相关的分析工具有使用过哪些？具体的性能调优步骤吗？

常见的jvm分析工具:

监视JVM
jps
jstat
jstatd
Jmc

故障排除
jcmd
jinfo
jhat
jmap
jsadebugd
jstack



对JVM内存的系统级的调优主要的目的是减少GC的频率和Full GC的次数。
1.Full GC
会对整个堆进行整理，包括Young、Tenured和Perm。Full GC因为需要对整个堆进行回收，所以比较慢，因此应该尽可能减少Full GC的次数。

2.导致Full GC的原因
年老代（Tenured）被写满
调优时尽量让对象在新生代GC时被回收、让对象在新生代多存活一段时间和不要创建过大的对象及数组避免直接在年老代创建对象 。
持久代Pemanet Generation空间不足
增大Perm Gen空间，避免太多静态对象 ，控制好新生代和年老代的比例
System.gc()被显示调用
垃圾回收不要手动触发，尽量依靠JVM自身的机制
在对JVM调优的过程中，很大一部分工作就是对于FullGC的调节，下面详细介绍对应JVM调优的方法和步骤。

**JVM性能调优方法和步骤**

1.监控GC的状态
使用各种JVM工具，查看当前日志，分析当前JVM参数设置，并且分析当前堆内存快照和gc日志，根据实际的各区域内存划分和GC执行时间，觉得是否进行优化。
举一个例子： 系统崩溃前的一些现象：

每次垃圾回收的时间越来越长，由之前的10ms延长到50ms左右，FullGC的时间也有之前的0.5s延长到4、5s
FullGC的次数越来越多，最频繁时隔不到1分钟就进行一次FullGC
年老代的内存越来越大并且每次FullGC后年老代没有内存被释放
之后系统会无法响应新的请求，逐渐到达OutOfMemoryError的临界值，这个时候就需要分析JVM内存快照dump。

2.生成堆的dump文件
通过JMX的MBean生成当前的堆（Heap）信息，大小为一个3G（整个堆的大小）的hprof文件，如果没有启动JMX可以通过Java的jmap命令来生成该文件。

3.分析dump文件
打开这个3G的堆信息文件，显然一般的Window系统没有这么大的内存，必须借助高配置的Linux，几种工具打开该文件： Visual VM
、IBM HeapAnalyzer、JDK 自带的Hprof工具、Mat(Eclipse专门的静态内存分析工具)推荐使用。
　　 注：文件太大，建议使用Eclipse专门的静态内存分析工具Mat打开分析。

4.分析结果，判断是否需要优化
如果各项参数设置合理，系统没有超时日志出现，GC频率不高，GC耗时不高，那么没有必要进行GC优化，如果GC时间超过1-3秒，或者频繁GC，则必须优化。
　　 注：如果满足下面的指标，则一般不需要进行GC：

Minor GC执行时间不到50ms；
Minor GC执行不频繁，约10秒一次；
Full GC执行时间不到1s；
Full GC执行频率不算频繁，不低于10分钟1次；
5.调整GC类型和内存分配
如果内存分配过大或过小，或者采用的GC收集器比较慢，则应该优先调整这些参数，并且先找1台或几台机器进行beta，然后比较优化过的机器和没有优化的机器的性能对比，并有针对性的做出最后选择。

6.不断分析和调整
通过不断的试验和试错，分析并找到最合适的参数，如果找到了最合适的参数，则将这些参数应用到所有服务器。



# MySQL的慢sql优化一般如何来做？除此外还有什么方法优化？

（1）数据库中设置SQL慢查询

set global slow_query_log=ON;

set global long_query_time=5000;

set global long_querise_not_using_indexes=ON;

（2）分析慢查询日志    

 直接分析mysql慢查询日志 ,利用explain关键字可以模拟优化器执行SQL查询语句，来分析sql慢查询语句

还可以通过show profile性能优化器,查看语句的具体执行过程,生命周期分析



# 线上的服务器监控指标，你认为哪些指标是最需要关注的？为什么？

**服务器监控**

在搭建服务器时，除了部署webapp之外，还需要服务的异常信息与服务器性能指标进行监控，一旦有异常则通知管理员。
   服务器使用Linux+Nginx-1.9.15+Tomcat7+Java搭建的。
   编写脚本检测错误日志和服务器性能指标，一旦新生错误日志或者性能降低到设定的阈值时，则使用云监控将报警上传到云账号。

**服务运行监控**

   错误日志包含以下三个方面：

nginx 错误信息监控(nginx.conf配置)
${NGINX_HOME}/logs/error.log
tomcat 错误信息监控(server.xml配置)
${TOMCAT_HOME}/logs/catalina.out
webapp错误信息监控(log4j)
${WEBAPP_HOME}/log/error

**机器性能指标**

   一般都会使用linux系统的机器作为服务器，那么当在上面搭建服务时，需要对一些常用的性能指标进行监控，那么一般包含哪些指标呢？

​	**指标**

- CPU(Load) CPU使用率/负载
- Memory 内存
- Disk 磁盘空间
- Disk I/O 磁盘I/O
- Network I/O 网络I/O
- Connect Num 连接数
- File Handle Num 文件句柄数

1.CPU

 机器的CPU占有率越高，说明机器处理越忙，运算型任务越多。一个任务可能不仅会有运算部分，还会有I/O(磁盘I/O与网络I/O)部分，当在处理I/O时，时间片未完其CPU也会释放，因此某个时间点的CPU占有率没有太大的意义，因此需要计算一段时间内的平均值，那么平均负载(Load Average)这个指标便能很好得对其进行表征。

2.Memory

内存也是系统运行性能的一个很重要的指标，如果一个机器内存不足，那么将会导致进程运行异常而退出。如果进程发生内存泄漏，则会导致大量内存被浪费而无足够可用内存。内存监控一般包括total(机器总内存)、free(机器可用内存)、swap(交换区大小)、cache(缓存大小)等。

3.Disk磁盘空间

机器的磁盘空间也是一个重要的指标，一旦使用率超过阈值而使得可用不足，那么就需要进行扩容或者清除一些无用的文件。

4.磁盘I/O

机器的磁盘空间也是一个重要的指标，一旦磁盘I/O过重，那么说明运行的进程在大量的文件读写并且cache命中率低。那么一个简单的方法便是增大文件缓存大小来提高命中率从而降低I/O。
   在Linux中，内核希望能尽可能产生次缺页中断（从文件缓存区读），并且能尽可能避免主缺页中断（从硬盘读），这样随着缺页中断的增多，文件缓存区也逐步增大，直到系统只有少量可用物理内存的时候 Linux 才开始释放一些不用的页。

5.网络I/O

 如果服务器网络连接过多，那么会造成大量的数据包在缓冲区长时间得不到处理，一旦缓冲区不足，便会造成数据包丢失问题，对于TCP，数据包丢失便会进行重传，这有会导致大量的重传；对于UDP，数据包丢失不会进行重传，那么数据便会丢失。因此，服务器的网络连接不宜过多，需要进行监控。
  服务器一般接收UDP与TCP请求，都是无状态连接，TCP(传输控制协议)是一种提供可靠的数据传输协议，UDP(用户数据报协议)是一种面向无连接的协议，即其传输简单但不可靠。

6.连接数

  对于每一台服务器，都应该限制同时连接数，但是这个阈值又不好确定，因此当监测到系统负载过重时，然后取其连接数，这个值便可作为参考值。

7.文件句柄数

 文件句柄数即当前打开的文件数，对于linux，系统默认支持的最大句柄数是1024，当然每个系统可以不一样，也可以修改，最大不能超过无符号整型最大值(65535)，可以使用ulimit -n命令进行查看，即因此如果同时打开的文件数超过这个数便会发生异常。因此这个指标也需要进行监控。



# soa和微服务的区别是什么？

　　首先SOA和微服务架构一个层面的东西，而对于ESB和微服务网关是一个层面的东西，一个谈到是架构风格和方法，一个谈的是实现工具或组件。

　　1、SOA（Service Oriented Architecture）“面向服务的架构”：他是一种设计方法，其中包含多个服务， 服务之间通过相互依赖最终提供一系列的功能。一个服务 通常以独立的形式存在与操作系统进程中。各个服务之间 通过网络调用。

　　2、微服务架构：其实和SOA架构类似，微服务是在SOA上做的升华，微服务架构强调的一个重点是“业务需要彻底的组件化和服务化”，原有的单个业务系统会拆分为多个可以独立开发、设计、运行的小应用。这些小应用之间通过服务完成交互和集成。



# 单机系统演变为分布式系统，会涉及到哪些技术的调整？请从前面负载到后端详细描述。

　**Web负载均衡**
　　
　　Web负载均衡（Load Balancing），简单地说就是给我们的服务器集群分配“工作任务”，而采用恰当的分配方式，对于保护处于后端的Web服务器来说，非常重要。



 **HTTP重定向**
　　
　　当用户发来请求的时候，Web服务器通过修改HTTP响应头中的Location标记来返回一个新的url，然后浏览器再继续请求这个新url，实际上就是页面重定向。通过重定向，来达到“负载均衡”的目标。

**反向代理负载均衡**
　　
　　反向代理服务的核心工作主要是转发HTTP请求，扮演了浏览器端和后台Web服务器中转的角色。因为它工作在HTTP层（应用层），也就是网络七层结构中的第七层，因此也被称为“七层负载均衡”。可以做反向代理的软件很多，比较常见的一种是Nginx。

　Nginx是一种非常灵活的反向代理软件，可以自由定制化转发策略，分配服务器流量的权重等。反向代理中，常见的一个问题，就是Web服务器存储的session数据，因为一般负载均衡的策略都是随机分配请求的。同一个登录用户的请求，无法保证一定分配到相同的Web机器上，会导致无法找到session的问题。



　解决方案主要有两种：
　　
  　　1. 配置反向代理的转发规则，让同一个用户的请求一定落到同一台机器上（通过分析cookie），复杂的转发规则将会消耗更多的CPU，也增加了代理服务器的负担。

  　　2. 将session这类的信息，专门用某个独立服务来存储，例如redis/memchache，这个方案是比较推荐的。

　　反向代理服务，也是可以开启缓存的，如果开启了，会增加反向代理的负担，需要谨慎使用。这种负载均衡策略实现和部署非常简单，而且性能表现也比较好。但是，它有“单点故障”的问题，如果挂了，会带来很多的麻烦。而且，到了后期Web服务器继续增加，它本身可能成为系统的瓶颈。

 **IP负载均衡**

　　IP负载均衡服务是工作在网络层（修改IP）和传输层（修改端口，第四层），比起工作在应用层（第七层）性能要高出非常多。原理是，他是对IP层的数据包的IP地址和端口信息进行修改，达到负载均衡的目的。这种方式，也被称为“四层负载均衡”。常见的负载均衡方式，是LVS（Linux Virtual Server，Linux虚拟服务），通过IPVS（IP Virtual Server，IP虚拟服务）来实现。

在负载均衡服务器收到客户端的IP包的时候，会修改IP包的目标IP地址或端口，然后原封不动地投递到内部网络中，数据包会流入到实际Web服务器。实际服务器处理完成后，又会将数据包投递回给负载均衡服务器，它再修改目标IP地址为用户IP地址，最终回到客户端。

　IP负载均衡的性能要高出Nginx的反向代理很多，它只处理到传输层为止的数据包，并不做进一步的组包，然后直接转发给实际服务器。不过，它的配置和搭建比较复杂。

**DNS负载均衡**

　　DNS（Domain Name System）负责域名解析的服务，域名url实际上是服务器的别名，实际映射是一个IP地址，解析过程，就是DNS完成域名到IP的映射。而一个域名是可以配置成对应多个IP的。因此，DNS也就可以作为负载均衡服务。

　这种负载均衡策略，配置简单，性能极佳。但是，不能自由定义规则，而且，变更被映射的IP或者机器故障时很麻烦，还存在DNS生效延迟的问题。

**Web系统的缓存机制的建立和优化**

​	 **MySQL数据库多台服务搭建**

​	建立MySQL主从，从库作为备份

​	MySQL读写分离，主库写，从库读。

​	主主互备。

 **MySQL数据库机器之间的数据同步**

当我们有多台MySQL，在业务高峰期，很可能出现两个库之间的数据有延迟的场景。并且，网络和机器负载等，也会影响数据同步的延迟。我们曾经遇到过，在日访问量接近1亿的特殊场景下，出现，从库数据需要很多天才能同步追上主库的数据。这种场景下，从库基本失去效用了。
　　
　　于是，解决同步问题，就是我们下一步需要关注的点。

​	 MySQL自带多线程同步

​	自己实现解析binlog，多线程写入。

**在Web服务器和数据库之间建立缓存**

​	**1. 页面静态化**

​	　用户访问网站的某个页面，页面上的大部分内容在很长一段时间内，可能都是没有变化的。例如一篇新闻报道，一旦发布几乎是不会修改内容的。这样的话，通过CGI生成的静态html页面缓存到Web服务器的磁盘本地。除了第一次，是通过动态CGI查询数据库获取之外，之后都直接将本地磁盘文件返回给用户。



​	**2. 单台内存缓存**

　通过页面静态化的例子中，我们可以知道将“缓存”搭建在Web机器本机是不好维护的，会带来更多问题（实际上，通过PHP的apc拓展，可通过Key/value操作Web服务器的本机内存）。因此，我们选择搭建的内存缓存服务，也必须是一个独立的服务。

​	**3. 内存缓存集群**

当我们搭建单台内存缓存完毕，我们又会面临单点故障的问题，因此，我们必须将它变成一个集群。简单的做法，是给他增加一个slave作为备份机器。但是，如果请求量真的很多，我们发现cache命中率不高，需要更多的机器内存呢？因此，我们更建议将它配置成一个集群。例如，类似redis cluster。
　　
　　Redis cluster集群内的Redis互为多组主从，同时每个节点都可以接受请求，在拓展集群的时候比较方便。客户端可以向任意一个节点发送请求，如果是它的“负责”的内容，则直接返回内容。否则，查找实际负责Redis节点，然后将地址告知客户端，客户端重新请求。

​	**4. 减少数据库“写”**

写的操作也是一个大的压力。写的操作，虽然无法减少，但是可以通过合并请求，来起到减轻压力的效果。这个时候，我们就需要在内存缓存集群和数据库集群之间，建立一个修改同步机制。
　　
　　先将修改请求生效在cache中，让外界查询显示正常，然后将这些sql修改放入到一个队列中存储起来，队列满或者每隔一段时间，合并为一个请求到数据库中更新数据库。

​	**5. NoSQL存储**

NoSQL存储，大部分都是采用key-value的方式，这里比较推荐使用Redis，Redis本身是一个内存cache，同时也可以当做一个存储来使用，让它直接将数据落地到磁盘。

这样的话，我们就将数据库中某些被频繁读写的数据，分离出来，放在我们新搭建的Redis存储集群中，又进一步减轻原来MySQL数据库的压力，同时因为Redis本身是个内存级别的Cache，读写的性能都会大幅度提升。

​	**6. 空节点查询问题**

当我们搭建完前面所说的全部服务，认为Web系统已经很强的时候。我们还是那句话，新的问题还是会来的。空节点查询，是指那些数据库中根本不存在的数据请求。例如，我请求查询一个不存在人员信息，系统会从各级缓存逐级查找，最后查到到数据库本身，然后才得出查找不到的结论，返回给前端。因为各级cache对它无效，这个请求是非常消耗系统资源的，而如果大量的空节点查询，是可以冲击到系统服务的。

**异地部署（地理分布式）**

​	　**一、 核心集中与节点分散**

1. 核心集中：实际部署过程中，总有一部分的数据和服务存在不可部署多套，或者部署多套成本巨大。而对于这些服务和数据，就仍然维持一套，而部署地点选择一个地域比较中心的地方，通过网络内部专线来和各个节点通讯。

  2. 节点分散：将一些服务部署为多套，分布在各个城市节点，让用户请求尽可能选择近的节点访问服务。

     　**二、 节点容灾和过载保护**

     节点容灾是指，某个节点如果发生故障时，我们需要建立一个机制去保证服务仍然可用。毫无疑问，这里比较常见的容灾方式，是切换到附近城市节点。假如系统的天津节点发生故障，那么我们就将网络流量切换到附近的北京节点上。考虑到负载均衡，可能需要同时将流量切换到附近的几个地域节点。另一方面，核心节点自身也是需要自己做好容灾和备份的，核心节点一旦故障，就会影响全国服务。
     　　
     　　过载保护，指的是一个节点已经达到最大容量，无法继续接接受更多请求了，系统必须有一个保护的机制。一个服务已经满负载，还继续接受新的请求，结果很可能就是宕机，影响整个节点的服务，为了至少保障大部分用户的正常使用，过载保护是必要的。
     　　
     　　解决过载保护，一般2个方向：
     　　

       　　1. 拒绝服务，检测到满负载之后，就不再接受新的连接请求。例如网游登入中的排队。
       　　2. 分流到其他节点。这种的话，系统实现更为复杂，又涉及到负载均衡的问题。

     

# 设计一个秒杀系统？

**秒杀系统的难点**

首先我们先看下秒杀场景的难点到底在哪？在秒杀场景中最大的问题在于容易产生大并发请求、产生超卖现象和性能问题，下面我们分别分析下下面这三个问题：

1）瞬时大并发：一提到秒杀系统给人最深刻的印象是超大的瞬时并发，这时你可以联想到小米手机的抢购场景，在小米手机抢购的场景一般都会有10w＋的用户同时访问一个商品页面去抢购手机，这就是一个典型的瞬时大并发，如果系统没有经过限流或者熔断处理，那么系统瞬间就会崩掉，就好像被DDos攻击一样；

2）超卖：秒杀除了大并发这样的难点，还有一个所有电商都会遇到的痛，那就是超卖，电商搞大促最怕什么？最怕的就是超卖，产生超卖了以后会影响到用户体验，会导致订单系统、库存系统、供应链等等，产生的问题是一系列的连锁反应，所以电商都不希望超卖发生，但是在大并发的场景最容易发生的就是超卖，不同线程读取到的当前库存数据可能下个毫秒就被其他线程修改了，如果没有一定的锁库存机制那么库存数据必然出错，都不用上万并发，几十并发就可以导致商品超卖；

3）性能：当遇到大并发和超卖问题后，必然会引出另一个问题，那就是性能问题，如何保证在大并发请求下，系统能够有好的性能，让用户能够有更好的体验，不然每个用户都等几十秒才能知道结果，那体验必然是很糟糕的；

**秒杀系统方案**

![](img\snipaste20200119_155836.png)

从整个秒杀系统的架构其实和一般的互联网系统架构本身没有太多的不同，核心理念还是通过缓存、异步、限流来保证系统的高并发和高可用。下面从一笔秒杀交易的流程来描述下秒杀系统架构设计的要点：

1）对于大促时候的秒杀活动，一般运营会配置静态的活动页面，配置静态活动页面主要有两个目的一方面是为了便于在各种社交媒体分发，另一方面是因为秒杀活动页的流量是大促期间最大的，通过配置成静态页面可以将页面发布在公有云上动态的横向扩展；

2）将秒杀活动的静态页面提前刷新到CDN节点，通过CDN节点的页面缓存来缓解访问压力和公司网络带宽，CDN上缓存js、css和图片；

3）将活动H5页面部署在公有云的web  server上，使用公有云最大的好处就是能够根据活动的火爆程度动态扩容而且成本较低，同时将访问压力隔离在公司系统外部；

4）在提供真正商品秒杀业务功能的app server上，需要进行交易限流、熔断控制，防止因为秒杀交易影响到其他正常服务的提供，我们在限流和熔断方面使用了hystrix，在核心交易的controller层通过hystrix进行交易并发限流控制，当交易流量超出我们设定的限流最大值时，会对新交易进行熔断处理固定返回静态失败报文。

5）服务降级处理，除了上面讲到的限流和熔断控制，我们还设定了降级开关，对于首页、购物车、订单查询、大数据等功能都会进行一定程度的服务降级，例如我们会对首页原先动态生成的大数据页面布局降级为所有人看到的是一样的页面、购物车也会降级为不在一级页面的tabbar上的购物车图标上显示商品数量、历史订单的查询也会提供时间周期较短的查询、大数据商品推荐也会提供一样的商品推荐，通过这样的降级处理能够很好的保证各个系统在大促期间能够正常的提供最基本的服务，保证用户能够正常下单完成付款。

6）上面介绍的都是如何保证能扛住高并发，下面介绍下整个方案中如何防止超卖现象的发生，我们日常的下单过程中防止超卖一般是通过在数据库上实施乐观锁来完成，使用乐观锁虽然比for update这种悲观锁方式性能要好很多，但是还是无法满足秒杀的上万并发需求，我们的方案其实也很简单实时库存的扣减在缓存中进行，异步扣减数据库中的库存，保证缓存中和数据库中库存的最终一致性。

在这个方案中我们使用的分布式缓存是redis，使用了codis集群方案稳定性和高可用方面还是比较有保证的，因为redis是单线程写，所以也不用担心线程安全的问题，redis自身就能够保证数据的强一致性，在下单的事务中包含了实时扣减缓存中的库存和异步发送队列，由队列处理器再异步从队列中取出订单根据订单信息扣减库存系统数据库中的商品数量。